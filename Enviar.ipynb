{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-21wiLf-gCD"
      },
      "source": [
        "# Programming Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxkainBa-gCF"
      },
      "source": [
        "## CNN classifier for the MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQKECTiE-gCG"
      },
      "source": [
        "### Instructions\n",
        "\n",
        "In this notebook, you will write code to build, compile and fit a convolutional neural network (CNN) model to the MNIST dataset of images of handwritten digits.\n",
        "\n",
        "Some code cells are provided you in the notebook. You should avoid editing provided code, and make sure to execute the cells in order to avoid unexpected errors. Some cells begin with the line:\n",
        "\n",
        "`#### GRADED CELL ####`\n",
        "\n",
        "Don't move or edit this first line - this is what the automatic grader looks for to recognise graded cells. These cells require you to write your own code to complete them, and are automatically graded when you submit the notebook. Don't edit the function name or signature provided in these cells, otherwise the automatic grader might not function properly. Inside these graded cells, you can use any functions or classes that are imported below, but make sure you don't use any variables that are outside the scope of the function.\n",
        "\n",
        "### How to submit\n",
        "\n",
        "Complete all the tasks you are asked for in the worksheet. When you have finished and are happy with your code, press the **Submit Assignment** button at the top of this notebook.\n",
        "\n",
        "### Let's get started!\n",
        "\n",
        "We'll start running some imports, and loading the dataset. Do not edit the existing imports in the following cell. If you would like to make further Tensorflow imports, you should add them here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "eR7qaZCl-gCJ"
      },
      "outputs": [],
      "source": [
        "#### PACKAGE IMPORTS ####\n",
        "\n",
        "# Run this cell first to import all required packages. Do not make any imports elsewhere in the notebook\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# If you would like to make further imports from Tensorflow, add them here\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Softmax, Conv2D, MaxPooling2D\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOQk31Sc-gCN"
      },
      "source": [
        "#### The MNIST dataset\n",
        "\n",
        "In this assignment, you will use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/). It consists of a training set of 60,000 handwritten digits with corresponding labels, and a test set of 10,000 images. The images have been normalised and centred. The dataset is frequently used in machine learning research, and has become a standard benchmark for image classification models.\n",
        "\n",
        "- Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. \"Gradient-based learning applied to document recognition.\" Proceedings of the IEEE, 86(11):2278-2324, November 1998.\n",
        "\n",
        "Your goal is to construct a neural network that classifies images of handwritten digits into one of 10 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOxMGi5e-gCP"
      },
      "source": [
        "#### Load and preprocess the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8zzRQzxA-gCQ"
      },
      "outputs": [],
      "source": [
        "# Run this cell to load the MNIST data\n",
        "\n",
        "mnist_data = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist_data.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEeA_9-6-gCV"
      },
      "source": [
        "First, preprocess the data by scaling the training and test images so their values lie in the range from 0 to 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "8AW1YX_9-gCX"
      },
      "outputs": [],
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function.\n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def scale_mnist_data(train_images, test_images):\n",
        "    \"\"\"\n",
        "    This function takes in the training and test images as loaded in the cell above, and scales them\n",
        "    so that they have minimum and maximum values equal to 0 and 1 respectively.\n",
        "    Your function should return a tuple (train_images, test_images) of scaled training and test images.\n",
        "    \"\"\"\n",
        "    # Scale training images between 0 and 1\n",
        "    min_value = np.min(train_images)\n",
        "    max_value = np.max(train_images)\n",
        "    train_images = (train_images - min_value) / (max_value - min_value)\n",
        "    \n",
        "    # Scale testing images between 0 and 1\n",
        "    test_images = (test_images - min_value) / (max_value - min_value)\n",
        "    \n",
        "    # Return scaled images\n",
        "    return (train_images, test_images)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "XgMBPB9d-gCa"
      },
      "outputs": [],
      "source": [
        "# Run your function on the input data\n",
        "\n",
        "scaled_train_images, scaled_test_images = scale_mnist_data(train_images, test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "g1r-ULOQv2o3"
      },
      "outputs": [],
      "source": [
        "# Add a dummy channel dimension\n",
        "\n",
        "scaled_train_images = scaled_train_images[..., np.newaxis]\n",
        "scaled_test_images = scaled_test_images[..., np.newaxis]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy--eSWq-gCc"
      },
      "source": [
        "#### Build the convolutional neural network model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rnippry-gCd"
      },
      "source": [
        "We are now ready to construct a model to fit to the data. Using the Sequential API, build your CNN model according to the following spec:\n",
        "\n",
        "* The model should use the `input_shape` in the function argument to set the input size in the first layer.\n",
        "* A 2D convolutional layer with a 3x3 kernel and 8 filters. Use 'SAME' zero padding and ReLU activation functions. Make sure to provide the `input_shape` keyword argument in this first layer.\n",
        "* A max pooling layer, with a 2x2 window, and default strides.\n",
        "* A flatten layer, which unrolls the input into a one-dimensional tensor.\n",
        "* Two dense hidden layers, each with 64 units and ReLU activation functions.\n",
        "* A dense output layer with 10 units and the softmax activation function.\n",
        "\n",
        "In particular, your neural network should have six layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "N-N7ArQ1-gCe"
      },
      "outputs": [],
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function.\n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def get_model(input_shape):\n",
        "    \"\"\"\n",
        "    This function should build a Sequential model according to the above specification. Ensure the\n",
        "    weights are initialised by providing the input_shape argument in the first layer, given by the\n",
        "    function argument.\n",
        "    Your function should return the model.\n",
        "    \"\"\"\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Conv2D(8, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "9L_2kj9A-gCi"
      },
      "outputs": [],
      "source": [
        "# Run your function to get the model\n",
        "\n",
        "model = get_model(scaled_train_images[0].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvrW1EA1-gCl"
      },
      "source": [
        "#### Compile the model\n",
        "\n",
        "You should now compile the model using the `compile` method. To do so, you need to specify an optimizer, a loss function and a metric to judge the performance of your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "_x9mU2Li-gCm"
      },
      "outputs": [],
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function.\n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def compile_model(model):\n",
        "    \"\"\"\n",
        "    This function takes in the model returned from your get_model function, and compiles it with an optimiser,\n",
        "    loss function and metric.\n",
        "    Compile the model using the Adam optimiser (with default settings), the cross-entropy loss function and\n",
        "    accuracy as the only metric.\n",
        "    Your function doesn't need to return anything; the model will be compiled in-place.\n",
        "    \"\"\"\n",
        "    # the model\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(), #learning_rate=0.005\n",
        "        loss= tf.keras.losses.CategoricalCrossentropy(), #from_logits=False\n",
        "        metrics=[tf.keras.metrics.CategoricalAccuracy()]\n",
        "    )\n",
        "    \n",
        "compile_model(model)\n",
        "\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "pY08R9yB-gCr"
      },
      "outputs": [],
      "source": [
        "# Run your function to compile the model\n",
        "\n",
        "compile_model(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHUcXibk-gCv"
      },
      "source": [
        "#### Fit the model to the training data\n",
        "\n",
        "Now you should train the model on the MNIST dataset, using the model's `fit` method. Set the training to run for 5 epochs, and return the training history to be used for plotting the learning curves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "cDnNXqN1-gCw"
      },
      "outputs": [],
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function.\n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def train_model(model, scaled_train_images, train_labels):\n",
        "    \"\"\"\n",
        "    This function should train the model for 5 epochs on the scaled_train_images and train_labels.\n",
        "    Your function should return the training history, as returned by model.fit.\n",
        "    \"\"\"\n",
        "    # Train the model\n",
        "    history = model.fit(scaled_train_images, train_labels, epochs=5, batch_size=256)\n",
        "    return history\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Y1n3wh49-gCz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None,), output.shape=(None, 10)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run your function to train the model\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaled_train_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[31], line 12\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, scaled_train_images, train_labels)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03mThis function should train the model for 5 epochs on the scaled_train_images and train_labels.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03mYour function should return the training history, as returned by model.fit.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscaled_train_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/backend/tensorflow/nn.py:572\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[0;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    567\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must be at least rank 1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m     )\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    573\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same rank \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(ndim). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     )\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n",
            "\u001b[0;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None,), output.shape=(None, 10)"
          ]
        }
      ],
      "source": [
        "# Run your function to train the model\n",
        "\n",
        "history = train_model(model, scaled_train_images, train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhd3yK0i-gC3"
      },
      "source": [
        "#### Plot the learning curves\n",
        "\n",
        "We will now plot two graphs:\n",
        "* Epoch vs accuracy\n",
        "* Epoch vs loss\n",
        "\n",
        "We will load the model history into a pandas `DataFrame` and use the `plot` method to output the required graphs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0t2Xjgq-gC4"
      },
      "outputs": [],
      "source": [
        "# Run this cell to load the model history into a pandas DataFrame\n",
        "\n",
        "frame = pd.DataFrame(history.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQqYQiR4-gC7"
      },
      "outputs": [],
      "source": [
        "# Run this cell to make the Accuracy vs Epochs plot\n",
        "\n",
        "acc_plot = frame.plot(y=\"accuracy\", title=\"Accuracy vs Epochs\", legend=False)\n",
        "acc_plot.set(xlabel=\"Epochs\", ylabel=\"Accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGgTGfH4-gDA"
      },
      "outputs": [],
      "source": [
        "# Run this cell to make the Loss vs Epochs plot\n",
        "\n",
        "acc_plot = frame.plot(y=\"loss\", title = \"Loss vs Epochs\",legend=False)\n",
        "acc_plot.set(xlabel=\"Epochs\", ylabel=\"Loss\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziq-tFlU-gDD"
      },
      "source": [
        "#### Evaluate the model\n",
        "\n",
        "Finally, you should evaluate the performance of your model on the test set, by calling the model's `evaluate` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSqA8zUi-gDE"
      },
      "outputs": [],
      "source": [
        "#### GRADED CELL ####\n",
        "\n",
        "# Complete the following function.\n",
        "# Make sure to not change the function name or arguments.\n",
        "\n",
        "def evaluate_model(model, scaled_test_images, test_labels):\n",
        "    \"\"\"\n",
        "    This function should evaluate the model on the scaled_test_images and test_labels.\n",
        "    Your function should return a tuple (test_loss, test_accuracy).\n",
        "    \"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSNhInQD-gDG"
      },
      "outputs": [],
      "source": [
        "# Run your function to evaluate the model\n",
        "\n",
        "test_loss, test_accuracy = evaluate_model(model, scaled_test_images, test_labels)\n",
        "print(f\"Test loss: {test_loss}\")\n",
        "print(f\"Test accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP09yVMK-gDK"
      },
      "source": [
        "#### Model predictions\n",
        "\n",
        "Let's see some model predictions! We will randomly select four images from the test data, and display the image and label for each.\n",
        "\n",
        "For each test image, model's prediction (the label with maximum probability) is shown, together with a plot showing the model's categorical distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrUM42t_-gDL"
      },
      "outputs": [],
      "source": [
        "# Run this cell to get model predictions on randomly selected test images\n",
        "\n",
        "num_test_images = scaled_test_images.shape[0]\n",
        "\n",
        "random_inx = np.random.choice(num_test_images, 4)\n",
        "random_test_images = scaled_test_images[random_inx, ...]\n",
        "random_test_labels = test_labels[random_inx, ...]\n",
        "\n",
        "predictions = model.predict(random_test_images)\n",
        "\n",
        "fig, axes = plt.subplots(4, 2, figsize=(16, 12))\n",
        "fig.subplots_adjust(hspace=0.4, wspace=-0.2)\n",
        "\n",
        "for i, (prediction, image, label) in enumerate(zip(predictions, random_test_images, random_test_labels)):\n",
        "    axes[i, 0].imshow(np.squeeze(image))\n",
        "    axes[i, 0].get_xaxis().set_visible(False)\n",
        "    axes[i, 0].get_yaxis().set_visible(False)\n",
        "    axes[i, 0].text(10., -1.5, f'Digit {label}')\n",
        "    axes[i, 1].bar(np.arange(len(prediction)), prediction)\n",
        "    axes[i, 1].set_xticks(np.arange(len(prediction)))\n",
        "    axes[i, 1].set_title(f\"Categorical distribution. Model prediction: {np.argmax(prediction)}\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y6mwJLs-gDP"
      },
      "source": [
        "Congratulations for completing this programming assignment! In the next week of the course we will take a look at including validation and regularisation in our model training, and introduce Keras callbacks."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "coursera": {
      "course_slug": "tensor-flow-2-1",
      "graded_item_id": "g0YqY",
      "launcher_item_id": "N6gmY"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
